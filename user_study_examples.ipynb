{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "from certa.explain import CertaExplainer\n",
    "from certa.local_explain import get_original_prediction, get_row\n",
    "from certa.utils import merge_sources\n",
    "\n",
    "from baselines.landmark import Landmark\n",
    "from baselines.mojito import Mojito\n",
    "import shap\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root_datadir = '../cheapER/datasets/'\n",
    "experiments_dir = '../examples/'\n",
    "dataset = 'dirty_dblp_acm'\n",
    "datadir = os.path.join(root_datadir, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lsource = pd.read_csv(datadir + '/tableA.csv')\n",
    "rsource = pd.read_csv(datadir + '/tableB.csv')\n",
    "gt = pd.read_csv(datadir + '/train.csv')\n",
    "valid = pd.read_csv(datadir + '/valid.csv')\n",
    "test = pd.read_csv(datadir + '/test.csv')\n",
    "\n",
    "test_df = merge_sources(test, 'ltable_', 'rtable_', lsource, rsource, ['label'], [])\n",
    "train_df = merge_sources(gt, 'ltable_', 'rtable_', lsource, rsource, ['label'], ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Costruzione indice degli embeddings.....Fatto. 400001 embeddings totali.\n",
      "* Creazione del modello per il calcolo degli embeddings....\n",
      "* Inizializzo il tokenizzatore.....Fatto: 400001 parole totali.\n",
      "* Preparazione della matrice di embedding.....Fatto. Dimensioni matrice embeddings: (400002, 300)\n",
      "\n",
      "°°° EMBEDDING MODEL °°°\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Tupla_A (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tupla_B (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_lookup (Embedding)    (None, None, 300)    120000600   Tupla_A[0][0]                    \n",
      "                                                                 Tupla_B[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 120,000,600\n",
      "Trainable params: 0\n",
      "Non-trainable params: 120,000,600\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   [(None, None, 300)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   [(None, None, 300)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          541200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 722,402\n",
      "Trainable params: 722,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "working on abt_buy\n",
      "reading data from ../cheapER/datasets/abt_buy\n",
      "data loaded\n",
      "loading model from models/saved/deeper/abt_buy\n"
     ]
    }
   ],
   "source": [
    "from models.utils import get_model\n",
    "model_name = 'ditto'\n",
    "save_path = 'models/saved/' + model_name + '/' + dataset\n",
    "model = get_model(model_name, save_path, datadir, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Avvio test metriche....\n",
      "-- Corpus size: 1916\n",
      "-- Non Match: 1710\n",
      "-- Match: 206\n",
      "* Preparazione input......Fatto. 1916 tuple totali, esempio label: 0 -> [1. 0.], Table1 shape: (1916, 79), Table2 shape: (1916, 46)\n",
      "* Evaluating: |\n",
      "Precision: 0.3068181818181818, Recall: 0.13106796116504854, f1-score: 0.1836734693877551\n",
      "Total retrieved: 88, retrieved/total matches: 27/206\n",
      "* Avvio test metriche....\n",
      "-- Corpus size: 1916\n",
      "-- Non Match: 1710\n",
      "-- Match: 206\n",
      "* Preparazione input......Fatto. 1916 tuple totali, esempio label: 0 -> [1. 0.], Table1 shape: (1916, 79), Table2 shape: (1916, 46)\n",
      "* Evaluating: |\n",
      "Precision: 0.6931818181818182, Recall: 0.03567251461988304, f1-score: 0.067853170189099\n",
      "Total retrieved: 88, retrieved/total no_matches: 61/1710\n",
      "0.1836734693877551\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = model.evaluation(test_df)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    return model.predict(x)\n",
    "def predict_fn_mojito(x):\n",
    "    return model.predict(x, mojito=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "certa_explainer = CertaExplainer(lsource, rsource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-523-c1917f28d075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-520-2feea3251fd5>\u001b[0m in \u001b[0;36mpredict_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fn_mojito\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmojito\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/certa/models/DeepER.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, given_columns, mojito, expand_dim, ignore_columns, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mx_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mx_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0mout_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nomatch_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'match_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mout_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/certa/models/DeepER.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data, model, embeddings_model, tokenizer)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# Crea matrici di tokens e labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mtable1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2InputsUnlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;31m# Calcola inputs di embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/certa/models/DeepER.py\u001b[0m in \u001b[0;36mdata2InputsUnlabel\u001b[0;34m(data, tokenizer)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Tokenizza le tuple e prepara l'input per il modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mtable1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Sperimentale: ordino gli attributi per lunghezza decrescente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# Attributi con molti tokens conengono più informazioni utili\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = predictions.loc[(predictions['label'] == 0) & (predictions['match_score'] > 0.5)]\n",
    "false_negatives = predictions.loc[(predictions['label'] == 1) & (predictions['match_score'] < 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "nm_cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "m_cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "rand_row =  false_positives.iloc[i]\n",
    "l_id = int(rand_row['ltable_id'])\n",
    "label = rand_row[\"label\"]\n",
    "l_tuple = lsource.iloc[l_id]\n",
    "r_id = int(rand_row['rtable_id'])\n",
    "r_tuple = rsource.iloc[r_id]\n",
    "rand_row.head()\n",
    "label = rand_row['label']\n",
    "\n",
    "item = get_row(l_tuple, r_tuple)\n",
    "n_item = item.drop(['ltable_id','rtable_id'],axis=1)\n",
    "n_item.reindex(sorted(n_item.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_prediction = false_negatives.iloc[i][['nomatch_score', 'match_score']]\n",
    "original_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = original_prediction[1]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[[label, score]], columns=['label','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(l_tuple).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(r_tuple).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "saliency_df, cf_summary, counterfactual_examples, triangles = certa_explainer.explain(l_tuple, r_tuple, predict_fn, num_triangles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_df.reindex(sorted(saliency_df.columns), axis=1).style.background_gradient(cmap=cm, axis=1, low=0.1, high=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_df.reindex(sorted(saliency_df.columns), axis=1).plot(kind='bar',title='certa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "landmark_explainer = Landmark(lambda x: predict_fn(x)['match_score'].values, test_df,\n",
    "                              lprefix='',\n",
    "                              exclude_attrs=['id', 'ltable_id', 'rtable_id', 'label'],\n",
    "                              rprefix='',\n",
    "                              split_expression=r' ')\n",
    "labelled_item = item.copy()\n",
    "labelled_item['label'] = int(label)\n",
    "labelled_item['id'] = i\n",
    "land_explanation = landmark_explainer.explain(labelled_item)\n",
    "land_exp = land_explanation.groupby('column')['impact'].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[land_exp.values()], columns=land_exp.keys()).reindex(sorted(land_exp.keys()), axis=1).style.background_gradient(cmap=cm, axis=1, low=0.2, high=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[land_exp.values()], columns=land_exp.keys()).reindex(sorted(land_exp.keys()), axis=1).plot(kind='bar',title='landmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shap_explainer = shap.KernelExplainer(lambda x: predict_fn(x)['match_score'].values,\n",
    "                                      train_df.drop(['label'], axis=1).astype(str)[:50],\n",
    "                                      link='identity')\n",
    "shap_instance = test_df.iloc[i, 1:].drop(['ltable_id', 'rtable_id']).astype(str)\n",
    "shap_values = shap_explainer.shap_values(shap_instance, nsamples=100)\n",
    "match_shap_values = shap_values\n",
    "shap_saliency = dict()\n",
    "for sv in range(len(match_shap_values)):\n",
    "    shap_saliency[train_df.columns[1 + sv]] = match_shap_values[sv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[shap_saliency.values()], columns=shap_saliency.keys()).reindex(sorted(shap_saliency.keys()), axis=1).style.background_gradient(cmap=cm, axis=1, low=0.2, high=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[shap_saliency.values()], columns=shap_saliency.keys()).reindex(sorted(shap_saliency.keys()), axis=1).plot(kind='bar',title='shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mojito = Mojito(test_df.columns,\n",
    "                attr_to_copy='left',\n",
    "                split_expression=\" \",\n",
    "                class_names=['no_match', 'match'],\n",
    "                lprefix='', rprefix='',\n",
    "                feature_selection='lasso_path')\n",
    "mojito_exp = mojito.drop(predict_fn_mojito, item,\n",
    "                              num_features=30,\n",
    "                              num_perturbation=100)\n",
    "mojito_exp = mojito_exp.groupby('attribute')['weight'].mean().to_dict()\n",
    "for f in item.columns:\n",
    "    if not f in mojito_exp.keys():\n",
    "        mojito_exp[f] = 0\n",
    "if 'id' in mojito_exp:\n",
    "    mojito_exp.pop('id', None)\n",
    "if 'ltable_id' in mojito_exp:\n",
    "    mojito_exp.pop('ltable_id', None)\n",
    "if 'rtable_id' in mojito_exp:\n",
    "    mojito_exp.pop('rtable_id', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[mojito_exp.values()], columns=mojito_exp.keys()).reindex(sorted(mojito_exp.keys()), axis=1).style.background_gradient(cmap=cm, axis=1, low=0.2, high=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[mojito_exp.values()], columns=mojito_exp.keys()).reindex(sorted(mojito_exp.keys()), axis=1).plot(kind='bar',title='mojito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "null_hyp = dict()\n",
    "for r in n_item.columns:\n",
    "    null_hyp[r] = random.uniform(-1, 1)\n",
    "null_hyp_saliency_df = pd.DataFrame(data=[null_hyp.values()], columns=null_hyp.keys())\n",
    "null_hyp_saliency_df.reindex(sorted(null_hyp.keys()), axis=1).style.background_gradient(cmap=cm, axis=1, low=0.2, high=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hyp_saliency_df.reindex(sorted(null_hyp.keys()), axis=1).plot(kind='bar',title='null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certa_e = saliency_df.copy().to_dict(orient='list')\n",
    "certa_e['type'] = 'certa'\n",
    "mojito_e = mojito_exp.copy()\n",
    "mojito_e['type'] = 'mojito'\n",
    "land_e = land_exp.copy()\n",
    "land_e['type'] = 'landmark'\n",
    "shap_e = shap_saliency.copy()\n",
    "shap_e['type'] = 'shap'\n",
    "null_e = null_hyp.copy()\n",
    "null_e['type'] = 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eig(explanation, agg=True):\n",
    "    print(explanation)\n",
    "    saliency = explanation.copy()\n",
    "    exp_type = saliency['type']\n",
    "    print(saliency.pop('type'))\n",
    "    scores_d = []\n",
    "    scores_c = []\n",
    "    scores = []\n",
    "    lt = l_tuple.copy()\n",
    "    rt = r_tuple.copy()\n",
    "    row = get_row(lt, rt)\n",
    "    orig = predict_fn(row)[['nomatch_score', 'match_score']].values[0][1]\n",
    "    for tk in np.arange(8):\n",
    "        scores.append(orig)\n",
    "        # get top k important attributes\n",
    "        if not agg and tk >= len(saliency):\n",
    "            break\n",
    "        if exp_type == 'certa':\n",
    "            if agg:\n",
    "                explanation_attributes = sorted(saliency, key=saliency.get, reverse=True)[:tk]\n",
    "            else:\n",
    "                explanation_attributes = [sorted(saliency, key=saliency.get, reverse=True)[tk]]\n",
    "        elif score < 0.5:\n",
    "            saliency = {k:v for k,v in saliency.items() if v < 0}\n",
    "            if agg:\n",
    "                explanation_attributes = sorted(saliency, key=saliency.get)[:tk]\n",
    "            else:\n",
    "                explanation_attributes = [sorted(saliency, key=saliency.get)[tk]]\n",
    "        else:\n",
    "            saliency = {k:v for k,v in saliency.items() if v > 0}\n",
    "            if agg:\n",
    "                explanation_attributes = sorted(saliency, key=saliency.get, reverse=True)[:tk]\n",
    "            else:\n",
    "                explanation_attributes = [sorted(saliency, key=saliency.get, reverse=True)[tk]]\n",
    "        print(explanation_attributes)\n",
    "        # change those attributes\n",
    "        try:\n",
    "            lt = l_tuple.copy()\n",
    "            rt = r_tuple.copy()\n",
    "            modified_row = get_row(lt, rt)\n",
    "            for e in explanation_attributes:\n",
    "                modified_row[e] = ''\n",
    "            modified_tuple_prediction = predict_fn(modified_row)[['nomatch_score', 'match_score']].values[0]\n",
    "            #print(modified_tuple_prediction)\n",
    "            #print(modified_row)\n",
    "            score_drop = modified_tuple_prediction[1]\n",
    "            \n",
    "            scores_d.append(score_drop)\n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "        try:\n",
    "            lt = l_tuple.copy()\n",
    "            rt = r_tuple.copy()\n",
    "            modified_row = get_row(lt, rt)\n",
    "            for e in explanation_attributes:\n",
    "                if e.startswith(lprefix):\n",
    "                    new_e = e.replace(lprefix, rprefix)\n",
    "                else:\n",
    "                    new_e = e.replace(rprefix, lprefix)\n",
    "                modified_row[e] = modified_row[new_e]\n",
    "            #print(modified_row)\n",
    "            modified_tuple_prediction = predict_fn(modified_row)[['nomatch_score', 'match_score']].values[0]\n",
    "            #print(modified_tuple_prediction)\n",
    "            score_copy = modified_tuple_prediction[1]\n",
    "            scores_c.append(score_copy)\n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "    pd.Series(scores_d,name='drop').plot(kind='line', ylim=(0.45,0.55), title=exp_type)\n",
    "    #pd.Series(scores_c,name='copy').plot(kind='line', ylim=(0.45,0.55), title=exp_type)\n",
    "    pd.Series(scores,name='pred').plot(kind='line', ylim=(0.45,0.55), title=exp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ltable_title': [0.5338983050847457], 'ltable_authors': [0.49152542372881347], 'ltable_venue': [0.49999999999999994], 'ltable_year': [0.49152542372881347], 'rtable_title': [0.20338983050847462], 'rtable_authors': [0.18644067796610173], 'rtable_venue': [0.18644067796610173], 'rtable_year': [0.18644067796610173], 'type': 'certa'}\n",
      "certa\n",
      "[]\n",
      "['ltable_title']\n",
      "['ltable_title', 'ltable_venue']\n",
      "['ltable_title', 'ltable_venue', 'ltable_authors']\n",
      "['ltable_title', 'ltable_venue', 'ltable_authors', 'ltable_year']\n",
      "['ltable_title', 'ltable_venue', 'ltable_authors', 'ltable_year', 'rtable_title']\n",
      "['ltable_title', 'ltable_venue', 'ltable_authors', 'ltable_year', 'rtable_title', 'rtable_authors']\n",
      "['ltable_title', 'ltable_venue', 'ltable_authors', 'ltable_year', 'rtable_title', 'rtable_authors', 'rtable_venue']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eig(certa_e, agg=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
