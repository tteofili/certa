{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "from certa.explain import CertaExplainer\n",
    "from certa.local_explain import get_original_prediction, get_row\n",
    "from certa.utils import merge_sources\n",
    "\n",
    "from baselines.landmark import Landmark\n",
    "from baselines.mojito import Mojito\n",
    "import shap\n",
    "\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root_datadir = '../cheapER/datasets/'\n",
    "experiments_dir = '../examples/'\n",
    "dataset = 'dirty_dblp_acm'\n",
    "datadir = os.path.join(root_datadir, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lsource = pd.read_csv(datadir + '/tableA.csv')\n",
    "rsource = pd.read_csv(datadir + '/tableB.csv')\n",
    "gt = pd.read_csv(datadir + '/train.csv')\n",
    "valid = pd.read_csv(datadir + '/valid.csv')\n",
    "test = pd.read_csv(datadir + '/test.csv')\n",
    "\n",
    "test_df = merge_sources(test, 'ltable_', 'rtable_', lsource, rsource, ['label'], [])\n",
    "train_df = merge_sources(gt, 'ltable_', 'rtable_', lsource, rsource, ['label'], ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "file models/saved/ditto/dirty_dblp_acm/config.json not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on dirty_dblp_acm\n",
      "reading data from ../cheapER/datasets/dirty_dblp_acm\n",
      "data loaded\n",
      "loading model from models/saved/ditto/dirty_dblp_acm\n"
     ]
    }
   ],
   "source": [
    "from models.utils import get_model\n",
    "model_name = 'ditto'\n",
    "save_path = 'models/saved/' + model_name + '/' + dataset\n",
    "model = get_model(model_name, save_path, datadir, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p, r, f1 = model.evaluation(test_df)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    return model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "certa_explainer = CertaExplainer(lsource, rsource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_venue</th>\n",
       "      <th>ltable_year</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_venue</th>\n",
       "      <th>rtable_year</th>\n",
       "      <th>classes</th>\n",
       "      <th>labels</th>\n",
       "      <th>nomatch_score</th>\n",
       "      <th>match_score</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>secure transaction processing in firm real-tim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>binto george , jayant r. haritsa</td>\n",
       "      <td>secure buffering in firm real-time database sy...</td>\n",
       "      <td>the vldb journal -- the international journal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491374</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>1225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clustering validity checking methods : part ii...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>maria halkidi , yannis batistakis , michalis v...</td>\n",
       "      <td>cluster validity methods : part i 2002</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495292</td>\n",
       "      <td>0.504708</td>\n",
       "      <td>574.0</td>\n",
       "      <td>749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>gerd g. hillebrand , peter buneman , susan b. ...</td>\n",
       "      <td>a query language and optimization techniques f...</td>\n",
       "      <td>sigmod conference</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fundamental techniques for order optimization ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487596</td>\n",
       "      <td>0.512404</td>\n",
       "      <td>561.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>structures for manipulating proposed updates i...</td>\n",
       "      <td>sigmod conference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>won kim</td>\n",
       "      <td>observations on the odmg-93 proposal for an ob...</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503002</td>\n",
       "      <td>0.496998</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>1307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>integrating a structured-text retrieval system...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>index nesting - an efficient approach to index...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483793</td>\n",
       "      <td>0.516207</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>1205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discovery of influence sets in frequently upda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>ioana stanoi , mirek riedewald , divyakant agr...</td>\n",
       "      <td>discovery of influence sets in frequently upda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496201</td>\n",
       "      <td>0.503799</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>1324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>0</td>\n",
       "      <td>s. sudarshan , divesh srivastava , raghu ramak...</td>\n",
       "      <td>space optimization in deductive databases acm ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>some issues in design of distributed deductive...</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476496</td>\n",
       "      <td>0.523504</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>efficient geometry-based similarity search of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fast parallel similarity search in multimedia ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476933</td>\n",
       "      <td>0.523067</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>1</td>\n",
       "      <td>viswanath poosala , phillip b. gibbons , yossi...</td>\n",
       "      <td>fast incremental maintenance of approximate hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fast incremental maintenance of approximate hi...</td>\n",
       "      <td>acm transactions on database systems ( tods )</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494144</td>\n",
       "      <td>0.505856</td>\n",
       "      <td>2451.0</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>0</td>\n",
       "      <td>peter z. revesz</td>\n",
       "      <td>safe query languages for constraint databases ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>introduction to constraint databases bart kuij...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482363</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>518.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2473 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                     ltable_authors  \\\n",
       "0        0                                                NaN   \n",
       "1        0                                                NaN   \n",
       "2        0  gerd g. hillebrand , peter buneman , susan b. ...   \n",
       "3        0                                                NaN   \n",
       "4        0                                                NaN   \n",
       "...    ...                                                ...   \n",
       "2468     1                                                NaN   \n",
       "2469     0  s. sudarshan , divesh srivastava , raghu ramak...   \n",
       "2470     0                                                NaN   \n",
       "2471     1  viswanath poosala , phillip b. gibbons , yossi...   \n",
       "2472     0                                    peter z. revesz   \n",
       "\n",
       "                                           ltable_title       ltable_venue  \\\n",
       "0     secure transaction processing in firm real-tim...                NaN   \n",
       "1     clustering validity checking methods : part ii...                NaN   \n",
       "2     a query language and optimization techniques f...  sigmod conference   \n",
       "3     structures for manipulating proposed updates i...  sigmod conference   \n",
       "4     integrating a structured-text retrieval system...               vldb   \n",
       "...                                                 ...                ...   \n",
       "2468  discovery of influence sets in frequently upda...                NaN   \n",
       "2469  space optimization in deductive databases acm ...                NaN   \n",
       "2470  efficient geometry-based similarity search of ...                NaN   \n",
       "2471  fast incremental maintenance of approximate hi...                NaN   \n",
       "2472  safe query languages for constraint databases ...                NaN   \n",
       "\n",
       "      ltable_year                                     rtable_authors  \\\n",
       "0          1997.0                   binto george , jayant r. haritsa   \n",
       "1          2002.0  maria halkidi , yannis batistakis , michalis v...   \n",
       "2          1996.0                                                NaN   \n",
       "3             NaN                                            won kim   \n",
       "4          1994.0                                                NaN   \n",
       "...           ...                                                ...   \n",
       "2468       2001.0  ioana stanoi , mirek riedewald , divyakant agr...   \n",
       "2469          NaN                                                NaN   \n",
       "2470       1999.0                                                NaN   \n",
       "2471       2002.0                                                NaN   \n",
       "2472       1998.0                                                NaN   \n",
       "\n",
       "                                           rtable_title  \\\n",
       "0     secure buffering in firm real-time database sy...   \n",
       "1                cluster validity methods : part i 2002   \n",
       "2     fundamental techniques for order optimization ...   \n",
       "3     observations on the odmg-93 proposal for an ob...   \n",
       "4     index nesting - an efficient approach to index...   \n",
       "...                                                 ...   \n",
       "2468  discovery of influence sets in frequently upda...   \n",
       "2469  some issues in design of distributed deductive...   \n",
       "2470  fast parallel similarity search in multimedia ...   \n",
       "2471  fast incremental maintenance of approximate hi...   \n",
       "2472  introduction to constraint databases bart kuij...   \n",
       "\n",
       "                                           rtable_venue  rtable_year  classes  \\\n",
       "0     the vldb journal -- the international journal ...          NaN        1   \n",
       "1                                     acm sigmod record          NaN        1   \n",
       "2                                                   NaN       1996.0        1   \n",
       "3                                     acm sigmod record       1994.0        0   \n",
       "4                                                   NaN          NaN        1   \n",
       "...                                                 ...          ...      ...   \n",
       "2468                                                NaN       2001.0        1   \n",
       "2469                              very large data bases          NaN        1   \n",
       "2470                                                NaN       1997.0        1   \n",
       "2471      acm transactions on database systems ( tods )       2002.0        1   \n",
       "2472                                                NaN       2002.0        1   \n",
       "\n",
       "      labels  nomatch_score  match_score  ltable_id  rtable_id  \n",
       "0          0       0.491374     0.508626     1496.0     1225.0  \n",
       "1          0       0.495292     0.504708      574.0      749.0  \n",
       "2          0       0.487596     0.512404      561.0     1957.0  \n",
       "3          0       0.503002     0.496998     1799.0     1307.0  \n",
       "4          0       0.483793     0.516207     1116.0     1205.0  \n",
       "...      ...            ...          ...        ...        ...  \n",
       "2468       1       0.496201     0.503799     2202.0     1324.0  \n",
       "2469       0       0.476496     0.523504       94.0     2277.0  \n",
       "2470       0       0.476933     0.523067        5.0     1921.0  \n",
       "2471       1       0.494144     0.505856     2451.0      539.0  \n",
       "2472       0       0.482363     0.517637     1577.0      518.0  \n",
       "\n",
       "[2473 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = predictions.loc[(predictions['label'] == 0) & (predictions['match_score'] > 0.5)]\n",
    "false_negatives = predictions.loc[(predictions['label'] == 1) & (predictions['match_score'] < 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "rand_row =  false_negatives.iloc[i]\n",
    "l_id = int(rand_row['ltable_id'])\n",
    "label = rand_row[\"label\"]\n",
    "l_tuple = lsource.iloc[l_id]\n",
    "r_id = int(rand_row['rtable_id'])\n",
    "r_tuple = rsource.iloc[r_id]\n",
    "rand_row.head()\n",
    "\n",
    "item = get_row(l_tuple, r_tuple)\n",
    "item.drop(['ltable_id','rtable_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nomatch_score    0.50709\n",
       "match_score      0.49291\n",
       "Name: 149, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_prediction = false_negatives.iloc[i][['nomatch_score', 'match_score']]\n",
    "original_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49291"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = original_prediction[1]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label = false_positives.iloc[i]['label']\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[label, score], columns=['label','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "saliency_df, cf_summary, counterfactual_examples, triangles = certa_explainer.explain(l_tuple, r_tuple, predict_fn, num_triangles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col0{\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col1,#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col3{\n",
       "            background-color:  #178d17;\n",
       "            color:  #000000;\n",
       "        }#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col2{\n",
       "            background-color:  #128a12;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col4{\n",
       "            background-color:  #b6e5b6;\n",
       "            color:  #000000;\n",
       "        }#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col5,#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col6,#T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col7{\n",
       "            background-color:  #c0eac0;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_d9b96162_8346_11ec_a6dc_24418c396bdd\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >ltable_title</th>        <th class=\"col_heading level0 col1\" >ltable_authors</th>        <th class=\"col_heading level0 col2\" >ltable_venue</th>        <th class=\"col_heading level0 col3\" >ltable_year</th>        <th class=\"col_heading level0 col4\" >rtable_title</th>        <th class=\"col_heading level0 col5\" >rtable_authors</th>        <th class=\"col_heading level0 col6\" >rtable_venue</th>        <th class=\"col_heading level0 col7\" >rtable_year</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col0\" class=\"data row0 col0\" >0.533898</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col1\" class=\"data row0 col1\" >0.491525</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col2\" class=\"data row0 col2\" >0.500000</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col3\" class=\"data row0 col3\" >0.491525</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col4\" class=\"data row0 col4\" >0.203390</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col5\" class=\"data row0 col5\" >0.186441</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col6\" class=\"data row0 col6\" >0.186441</td>\n",
       "                        <td id=\"T_d9b96162_8346_11ec_a6dc_24418c396bddrow0_col7\" class=\"data row0 col7\" >0.186441</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f779a6400>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saliency_df.style.background_gradient(cmap=cm, axis=1, low=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "landmark_explainer = Landmark(lambda x: predict_fn(x)['match_score'].values, test_df,\n",
    "                              lprefix='',\n",
    "                              exclude_attrs=['id', 'ltable_id', 'rtable_id', 'label'],\n",
    "                              rprefix='',\n",
    "                              split_expression=r' ')\n",
    "labelled_item = item.copy()\n",
    "labelled_item['label'] = int(label)\n",
    "labelled_item['id'] = i\n",
    "land_explanation = landmark_explainer.explain(labelled_item)\n",
    "land_exp = land_explanation.groupby('column')['impact'].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col0{\n",
       "            background-color:  #1f911f;\n",
       "            color:  #000000;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col1{\n",
       "            background-color:  #85ca85;\n",
       "            color:  #000000;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col2{\n",
       "            background-color:  #47a747;\n",
       "            color:  #000000;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col3{\n",
       "            background-color:  #c0eac0;\n",
       "            color:  #000000;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col4{\n",
       "            background-color:  #aadeaa;\n",
       "            color:  #000000;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col5{\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col6{\n",
       "            background-color:  #94d294;\n",
       "            color:  #000000;\n",
       "        }#T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col7{\n",
       "            background-color:  #5db35d;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_127f00ac_8346_11ec_a6dc_24418c396bdd\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >ltable_authors</th>        <th class=\"col_heading level0 col1\" >ltable_title</th>        <th class=\"col_heading level0 col2\" >ltable_venue</th>        <th class=\"col_heading level0 col3\" >ltable_year</th>        <th class=\"col_heading level0 col4\" >rtable_authors</th>        <th class=\"col_heading level0 col5\" >rtable_title</th>        <th class=\"col_heading level0 col6\" >rtable_venue</th>        <th class=\"col_heading level0 col7\" >rtable_year</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col0\" class=\"data row0 col0\" >0.001285</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col1\" class=\"data row0 col1\" >-0.001959</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col2\" class=\"data row0 col2\" >0.000028</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col3\" class=\"data row0 col3\" >-0.003825</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col4\" class=\"data row0 col4\" >-0.003141</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col5\" class=\"data row0 col5\" >0.002299</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col6\" class=\"data row0 col6\" >-0.002410</td>\n",
       "                        <td id=\"T_127f00ac_8346_11ec_a6dc_24418c396bddrow0_col7\" class=\"data row0 col7\" >-0.000666</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f77d19ba8>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=[land_exp.values()], columns=land_exp.keys()).style.background_gradient(cmap=cm, axis=1, low=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shap_explainer = shap.KernelExplainer(lambda x: predict_fn(x)['match_score'].values,\n",
    "                                      train_df.drop(['label'], axis=1).astype(str)[:50],\n",
    "                                      link='identity')\n",
    "shap_instance = test_df.iloc[i, 1:].drop(['ltable_id', 'rtable_id']).astype(str)\n",
    "shap_values = shap_explainer.shap_values(shap_instance, nsamples=100)\n",
    "match_shap_values = shap_values\n",
    "shap_saliency = dict()\n",
    "for sv in range(len(match_shap_values)):\n",
    "    shap_saliency[train_df.columns[1 + sv]] = match_shap_values[sv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_saliency.style.background_gradient(cmap=cm, axis=1, low=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mojito = Mojito(test_df.columns,\n",
    "                attr_to_copy='left',\n",
    "                split_expression=\" \",\n",
    "                class_names=['no_match', 'match'],\n",
    "                lprefix='', rprefix='',\n",
    "                feature_selection='lasso_path')\n",
    "mojito_exp = mojito.drop(predict_fn_mojito, item,\n",
    "                              num_features=15,\n",
    "                              num_perturbation=100)\n",
    "mojito_exp = mojito_exp.groupby('attribute')['weight'].mean().to_dict()\n",
    "if 'id' in mojito_exp:\n",
    "    mojito_exp.pop('id', None)\n",
    "if 'ltable_id' in mojito_exp:\n",
    "    mojito_exp.pop('ltable_id', None)\n",
    "if 'rtable_id' in mojito_exp:\n",
    "    mojito_exp.pop('rtable_id', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mojito_exp.style.background_gradient(cmap=cm, axis=1, low=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saliencies = []\n",
    "saliencies.append(certa_saliency.copy())\n",
    "saliencies.append(mojito_saliency.copy())\n",
    "saliencies.append(landmark_saliency.copy())\n",
    "saliencies.append(shap_saliency.copy())\n",
    "\n",
    "lprefix = 'ltable_'\n",
    "rprefix = 'rtable_'\n",
    "\n",
    "k = 1\n",
    "eval_series = pd.Series()\n",
    "# eval saliencies\n",
    "for saliency in saliencies:\n",
    "    print(saliency)\n",
    "    # get top k important attributes\n",
    "    exp_type = saliency['type']\n",
    "    print(saliency.pop('type'))\n",
    "    if exp_type == 'certa':\n",
    "        explanation_attributes = sorted(saliency, key=saliency.get, reverse=True)[:k]\n",
    "    elif score < 0.5:\n",
    "        saliency = {k:v for k,v in saliency.items() if v < 0}\n",
    "        explanation_attributes = sorted(saliency, key=saliency.get)[:k]\n",
    "    else:\n",
    "        saliency = {k:v for k,v in saliency.items() if v > 0}\n",
    "        explanation_attributes = sorted(saliency, key=saliency.get, reverse=True)[:k]\n",
    "\n",
    "    # change those attributes\n",
    "    try:\n",
    "        lt = l_tuple.copy()\n",
    "        rt = r_tuple.copy()\n",
    "        modified_row = get_row(lt, rt)\n",
    "        for e in explanation_attributes:\n",
    "            modified_row[e] = ''\n",
    "        modified_tuple_prediction = \\\n",
    "            predict_fn(modified_row)[['nomatch_score', 'match_score']].values[0]\n",
    "        #print(modified_tuple_prediction)\n",
    "        #print(modified_row)\n",
    "        score_drop = modified_tuple_prediction[1]\n",
    "        eval_series['top_' + exp_type + '_' + model.name] = explanation_attributes\n",
    "        eval_series['score_drop_' + exp_type + '_' + model.name] = score_drop\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "    try:\n",
    "        lt = l_tuple.copy()\n",
    "        rt = r_tuple.copy()\n",
    "        modified_row = get_row(lt, rt)\n",
    "        for e in explanation_attributes:\n",
    "            if e.startswith(lprefix):\n",
    "                new_e = e.replace(lprefix, rprefix)\n",
    "            else:\n",
    "                new_e = e.replace(rprefix, lprefix)\n",
    "            modified_row[e] = modified_row[new_e]\n",
    "        #print(modified_row)\n",
    "        modified_tuple_prediction = \\\n",
    "            predict_fn(modified_row)[['nomatch_score', 'match_score']].values[0]\n",
    "        #print(modified_tuple_prediction)\n",
    "        score_copy = modified_tuple_prediction[1]\n",
    "        eval_series['score_copy_' + exp_type + '_' + model.name] = score_copy\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "print(eval_series)\n",
    "print(cf_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "attributes = cf_summary.keys()[0].split('/')\n",
    "print(attributes)\n",
    "ex = counterfactual_examples[counterfactual_examples['alteredAttributes'].apply(lambda x: np.all([*map(lambda l: l in x, attributes)]))]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn(pd.DataFrame(ex))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
